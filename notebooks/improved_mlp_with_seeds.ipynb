{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom catboost import CatBoostClassifier, Pool\nfrom scipy.sparse import csr_matrix\nfrom sklearn.model_selection import train_test_split\n\n# pd.set_option('display.max_columns', None)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-30T08:04:47.468795Z","iopub.execute_input":"2025-09-30T08:04:47.46938Z","iopub.status.idle":"2025-09-30T08:04:52.816506Z","shell.execute_reply.started":"2025-09-30T08:04:47.469349Z","shell.execute_reply":"2025-09-30T08:04:52.815728Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# loading data\ntrain_dr = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest_dr = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\ntrain_dr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T08:04:55.294346Z","iopub.execute_input":"2025-09-30T08:04:55.294752Z","iopub.status.idle":"2025-09-30T08:04:59.278745Z","shell.execute_reply.started":"2025-09-30T08:04:55.294729Z","shell.execute_reply":"2025-09-30T08:04:59.278077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# reproducibility package\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T08:05:09.97299Z","iopub.execute_input":"2025-09-30T08:05:09.973288Z","iopub.status.idle":"2025-09-30T08:05:09.983266Z","shell.execute_reply.started":"2025-09-30T08:05:09.973266Z","shell.execute_reply":"2025-09-30T08:05:09.982447Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dr.info()\nprint('\\n'f'Missing values: {train_dr.isna().sum().sum()}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:01:20.497079Z","iopub.execute_input":"2025-09-29T13:01:20.497361Z","iopub.status.idle":"2025-09-29T13:01:20.563438Z","shell.execute_reply.started":"2025-09-29T13:01:20.497336Z","shell.execute_reply":"2025-09-29T13:01:20.562564Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CatBoost baseline","metadata":{}},{"cell_type":"code","source":"X = train_dr.drop(['label'], axis=1)\ny = train_dr.label\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED, shuffle=True, stratify=y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T08:00:02.766359Z","iopub.execute_input":"2025-09-24T08:00:02.767019Z","iopub.status.idle":"2025-09-24T08:00:03.087571Z","shell.execute_reply.started":"2025-09-24T08:00:02.766995Z","shell.execute_reply":"2025-09-24T08:00:03.086785Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create a sparse matrix\nXtr = csr_matrix(X_train.astype('float32') / 255.0)\nXvl = csr_matrix(X_val.astype('float32') / 255.0)\ntrain_pool = Pool(Xtr, label=y_train)\nval_pool = Pool(Xvl, label=y_val)\ntest_dr_pool = Pool(test_dr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T09:56:05.520453Z","iopub.execute_input":"2025-09-02T09:56:05.521195Z","iopub.status.idle":"2025-09-02T09:56:06.58491Z","shell.execute_reply.started":"2025-09-02T09:56:05.521163Z","shell.execute_reply":"2025-09-02T09:56:06.584106Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf = CatBoostClassifier(iterations=2000,\n                         loss_function='MultiClass',\n                         eval_metric='Accuracy',\n                         task_type='GPU',\n                         random_state=SEED)\n\nclf.fit(\n    train_pool,\n    eval_set=val_pool,\n    verbose=50,\n    use_best_model=True,\n    early_stopping_rounds=150\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T15:28:36.271747Z","iopub.execute_input":"2025-09-01T15:28:36.272277Z","iopub.status.idle":"2025-09-01T15:29:00.805625Z","shell.execute_reply.started":"2025-09-01T15:28:36.272253Z","shell.execute_reply":"2025-09-01T15:29:00.804905Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**score 0.96328**","metadata":{}},{"cell_type":"markdown","source":"# MLP","metadata":{}},{"cell_type":"markdown","source":"## Default Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nfrom torch.utils.data import TensorDataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T08:05:41.166809Z","iopub.execute_input":"2025-09-30T08:05:41.167616Z","iopub.status.idle":"2025-09-30T08:05:41.171065Z","shell.execute_reply.started":"2025-09-30T08:05:41.167588Z","shell.execute_reply":"2025-09-30T08:05:41.170469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train data preparation\nX = train_dr.drop('label', axis=1).values.astype('float32') / 255.0\ny = train_dr.label.values.astype('int64')\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED, shuffle=True, stratify=y)\n\nX_train_tz = torch.from_numpy(X_train)\nX_val_tz = torch.from_numpy(X_val)\ny_train_tz = torch.from_numpy(y_train)\ny_val_tz = torch.from_numpy(y_val)\n\ntrain_dataset = TensorDataset(X_train_tz, y_train_tz)\nval_dataset = TensorDataset(X_val_tz, y_val_tz)\n\ng = torch.Generator()\ng.manual_seed(SEED)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, generator=g)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T15:45:18.012948Z","iopub.execute_input":"2025-09-26T15:45:18.013648Z","iopub.status.idle":"2025-09-26T15:45:18.55537Z","shell.execute_reply.started":"2025-09-26T15:45:18.013615Z","shell.execute_reply":"2025-09-26T15:45:18.55454Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test data preparation\nX_test = test_dr.values.astype('float32') / 255.0\nX_test_tz = torch.from_numpy(X_test)\ntest_loader = DataLoader(TensorDataset(X_test_tz), batch_size=256, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T15:45:20.592583Z","iopub.execute_input":"2025-09-26T15:45:20.593107Z","iopub.status.idle":"2025-09-26T15:45:20.658911Z","shell.execute_reply.started":"2025-09-26T15:45:20.593048Z","shell.execute_reply":"2025-09-26T15:45:20.658105Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create model\nclass MLP_Default(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(784, 256), nn.ReLU(),\n            nn.Linear(256, 128), nn.ReLU(),\n            nn.Linear(128, 10)\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"execution":{"iopub.status.busy":"2025-09-02T12:56:58.717924Z","iopub.execute_input":"2025-09-02T12:56:58.718403Z","iopub.status.idle":"2025-09-02T12:56:58.72247Z","shell.execute_reply.started":"2025-09-02T12:56:58.71838Z","shell.execute_reply":"2025-09-02T12:56:58.721745Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = MLP_Default().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nloss_func = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2025-09-02T12:57:00.419383Z","iopub.execute_input":"2025-09-02T12:57:00.420043Z","iopub.status.idle":"2025-09-02T12:57:03.019838Z","shell.execute_reply.started":"2025-09-02T12:57:00.420017Z","shell.execute_reply":"2025-09-02T12:57:03.019284Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_accuracy = 0.0\nbest_state = None\n\nfor epoch in range(30):\n    # train\n    model.train()\n    for X_tr, y_tr in train_loader:\n        X_tr, y_tr = X_tr.to(device), y_tr.to(device)\n        optimizer.zero_grad()\n        loss = loss_func(model(X_tr), y_tr)\n        loss.backward()\n        optimizer.step()\n\n    # eval\n    model.eval()\n    correct = total_obj = 0\n    with torch.no_grad():\n        for X_vl, y_vl in val_loader:\n            X_vl, y_vl = X_vl.to(device), y_vl.to(device)\n            pred = model(X_vl).argmax(1)\n            correct += (pred == y_vl).sum().item()\n            total_obj += y_vl.size(0)\n\n    val_accuracy = correct / total_obj\n    print(f\"epoch {epoch+1}: val_accuracy={val_accuracy:.4f}\")\n\n    # save best parameters\n    if val_accuracy > best_accuracy:\n        best_accuracy = val_accuracy\n        best_state = model.state_dict()\n        print(f\"New best! Saving model with accuracy={best_accuracy:.4f}\")\n\n# load the best weights\nmodel.load_state_dict(best_state)","metadata":{"execution":{"iopub.status.busy":"2025-09-02T13:08:29.344077Z","iopub.execute_input":"2025-09-02T13:08:29.344367Z","iopub.status.idle":"2025-09-02T13:09:02.63408Z","shell.execute_reply.started":"2025-09-02T13:08:29.344347Z","shell.execute_reply":"2025-09-02T13:09:02.633477Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**score 0.97703**","metadata":{}},{"cell_type":"markdown","source":"## Promoted Model","metadata":{}},{"cell_type":"markdown","source":"*I will train the model using augmentations, and I have also improved it by adding dropout, BatchNorm1d, a scheduler, and so on. Predictions will be made using the TTA method with averaging over multiple predictions. The final prediction will be obtained by averaging the predictions across different seeds.*","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport torchvision.transforms as T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T09:43:28.907951Z","iopub.execute_input":"2025-09-30T09:43:28.908239Z","iopub.status.idle":"2025-09-30T09:43:28.912162Z","shell.execute_reply.started":"2025-09-30T09:43:28.908217Z","shell.execute_reply":"2025-09-30T09:43:28.911439Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# average with different seeds\nSEEDS = [65, 233, 9499]\nSPLIT_SEED = 42\n\ndef set_global_seed(seed: int):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T09:43:30.474898Z","iopub.execute_input":"2025-09-30T09:43:30.475209Z","iopub.status.idle":"2025-09-30T09:43:30.480256Z","shell.execute_reply.started":"2025-09-30T09:43:30.475184Z","shell.execute_reply":"2025-09-30T09:43:30.479466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# preparing training data\nX = train_dr.drop('label', axis=1).values.astype('uint8')\ny = train_dr.label.values.astype('int64')\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=SPLIT_SEED, shuffle=True, stratify=y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T09:43:32.653401Z","iopub.execute_input":"2025-09-30T09:43:32.653703Z","iopub.status.idle":"2025-09-30T09:43:33.046033Z","shell.execute_reply.started":"2025-09-30T09:43:32.653682Z","shell.execute_reply":"2025-09-30T09:43:33.045182Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# augmentation\ntrain_transform = T.Compose([\n    T.ToPILImage(),    # (28 x 28) dtype=PIL.Image [0..255]\n    T.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.95, 1.05), shear=5),\n    T.ToTensor(),    # (1, 28 x 28) dtype=torch.float32 [0..1]\n])\n\neval_transform = T.Compose([\n    T.ToPILImage(),\n    T.ToTensor(),\n])\n\n# class for online augmentation\nclass FlatAugDataset(Dataset):\n    def __init__(self, X, y=None, transform=None):\n        self.X = X\n        self.y = y\n        self.transform = transform\n\n    def __len__(self):\n        return self.X.shape[0]\n\n    def __getitem__(self, idx):\n        x = self.X[idx].reshape(28, 28)    # (784) dtype=uint8 [0..255]  ->  (28 x 28) dtype=uint8 [0..255]\n        x = self.transform(x)    # tensor (1, 28 x 28) dtype=torch.float32 [0..1]\n        x_vec = x.view(-1)    # (784) dtype=torch.float32 [0..1]\n        if self.y is None:\n            return x_vec\n        return x_vec, torch.tensor(self.y[idx], dtype=torch.long)\n\n# preparing test data\nX_test = test_dr.values.astype('uint8')\ntest_dataset = FlatAugDataset(X_test, y=None, transform=eval_transform)\ntest_loader  = DataLoader(test_dataset,  batch_size=256, shuffle=False, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T09:43:35.545722Z","iopub.execute_input":"2025-09-30T09:43:35.546006Z","iopub.status.idle":"2025-09-30T09:43:35.572272Z","shell.execute_reply.started":"2025-09-30T09:43:35.545976Z","shell.execute_reply":"2025-09-30T09:43:35.571727Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_loaders(seed: int):\n    \"\"\"\n    Loader factory for train/val for a specific seed\n    \"\"\"\n    # Datasets\n    train_dataset = FlatAugDataset(X_train, y_train, transform=train_transform)\n    val_dataset = FlatAugDataset(X_val, y_val, transform=eval_transform)\n    \n    # DataLoaders\n    g = torch.Generator()\n    g.manual_seed(seed)  \n\n    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True,  generator=g, pin_memory=True)\n    val_loader   = DataLoader(val_dataset,   batch_size=64, shuffle=False, pin_memory=True)\n    return train_loader, val_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T09:43:38.637987Z","iopub.execute_input":"2025-09-30T09:43:38.63824Z","iopub.status.idle":"2025-09-30T09:43:38.643144Z","shell.execute_reply.started":"2025-09-30T09:43:38.638222Z","shell.execute_reply":"2025-09-30T09:43:38.642406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MLP_Maxed(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fe = nn.Sequential(\n            nn.Linear(784, 1024),\n            nn.BatchNorm1d(1024),\n            nn.GELU(),\n            nn.Dropout(0.1),\n\n            nn.Linear(1024, 512),\n            nn.BatchNorm1d(512),\n            nn.GELU(),\n            nn.Dropout(0.1),\n\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.GELU(),\n            nn.Dropout(0.1),\n        )\n        self.head = nn.Linear(256, 10)\n\n        # kaiming init for Linear - under ReLU/GELU\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n                nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        x = self.fe(x)\n        return self.head(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T09:43:41.181712Z","iopub.execute_input":"2025-09-30T09:43:41.181978Z","iopub.status.idle":"2025-09-30T09:43:41.187796Z","shell.execute_reply.started":"2025-09-30T09:43:41.181957Z","shell.execute_reply":"2025-09-30T09:43:41.187173Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nEPOCHS = 35\n\ndef build_model_and_optim():\n    model = MLP_Maxed().to(device)\n\n    optimizer = torch.optim.AdamW(\n        model.parameters(), lr=2e-3, weight_decay=1e-2\n    )\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer, T_max=EPOCHS\n    )\n    loss_func = nn.CrossEntropyLoss(label_smoothing=0.1)\n\n    return model, optimizer, scheduler, loss_func","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T09:43:44.597168Z","iopub.execute_input":"2025-09-30T09:43:44.597886Z","iopub.status.idle":"2025-09-30T09:43:44.678327Z","shell.execute_reply.started":"2025-09-30T09:43:44.597862Z","shell.execute_reply":"2025-09-30T09:43:44.677585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_and_select_best(model, optimizer, scheduler, loss_func,\n                          train_loader, val_loader):\n    \"\"\"\n    The function returns the best model weights and accuracy value for a specific seed\n    \"\"\"\n    best_acc = -1.0\n    best_state = None\n\n    for epoch in range(EPOCHS):\n        # train\n        model.train()\n        for X_tr, y_tr in train_loader:\n            X_tr = X_tr.to(device, non_blocking=True)\n            y_tr = y_tr.to(device, non_blocking=True)\n            optimizer.zero_grad(set_to_none=True) \n            logits = model(X_tr)\n            loss = loss_func(logits, y_tr)\n            loss.backward()\n            optimizer.step()\n        scheduler.step()\n\n        # eval\n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for X_vl, y_vl in val_loader:\n                X_vl = X_vl.to(device, non_blocking=True)\n                y_vl = y_vl.to(device, non_blocking=True)\n                logits = model(X_vl)\n                pred = logits.argmax(dim=1)\n                correct += (pred == y_vl).sum().item()\n                total += y_vl.size(0)\n\n        val_acc = correct / total\n        print(f\"epoch {epoch+1}: val_accuracy={val_acc:.4f}\")\n\n        # save best parameters\n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n            print(f\"New best! Saving model with accuracy={best_acc:.4f}\")\n\n    return best_state, best_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T09:43:48.58586Z","iopub.execute_input":"2025-09-30T09:43:48.586168Z","iopub.status.idle":"2025-09-30T09:43:48.593185Z","shell.execute_reply.started":"2025-09-30T09:43:48.586146Z","shell.execute_reply":"2025-09-30T09:43:48.592424Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TTA and averaging by seeds\nbase_eval_tf = T.Compose([T.ToPILImage(), T.ToTensor()])    # \"as is\"\ntta_transforms = [\n    base_eval_tf,\n    T.Compose([T.ToPILImage(), T.RandomAffine(degrees=8,  translate=(0.08, 0.08)), T.ToTensor()]),\n    T.Compose([T.ToPILImage(), T.RandomAffine(degrees=0,  translate=(0.10, 0.00), scale=(0.98, 1.02)), T.ToTensor()]),\n    T.Compose([T.ToPILImage(), T.RandomAffine(degrees=10, translate=(0.00, 0.08), shear=5), T.ToTensor()]),\n]\n\nall_test_probs = []\n\nfor seed in SEEDS:\n    print(f\"\\n=== [seed={seed}] training started ===\")\n    set_global_seed(seed)\n    train_loader, val_loader = make_loaders(seed)\n    model, optimizer, scheduler, loss_func = build_model_and_optim()\n\n    best_state, best_acc = train_and_select_best(\n        model, optimizer, scheduler, loss_func,\n        train_loader, val_loader)\n\n    # load the best weights of the model for this seed\n    model.load_state_dict(best_state)\n    \n    sum_probs = None\n    for tf in tta_transforms:      \n        test_dataset.transform = tf\n        model.eval()\n        probs_chunks = []\n        with torch.no_grad():\n            for X in test_loader:\n                X = X.to(device, non_blocking=True)\n                logits = model(X)    # (B, C)\n                probs_chunks.append(torch.softmax(logits, dim=1))\n        probs = torch.cat(probs_chunks, dim=0)    # (N, C)\n        sum_probs = probs if sum_probs is None else (sum_probs + probs)\n\n    avg_probs_seed = sum_probs / len(tta_transforms)    # (N, C)\n    all_test_probs.append(avg_probs_seed.cpu())\n    print(f\"[seed={seed}] TTA predictions ready.\")\n\n# average by seeds\navg_probs = torch.stack(all_test_probs, dim=0).mean(dim=0)  # (3, N, C) -> (N, C)\npreds = avg_probs.argmax(dim=1).numpy()\nprint(\"\\n=== Ensemble across seeds complete. Predictions ready. ===\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T09:43:54.419025Z","iopub.execute_input":"2025-09-30T09:43:54.419309Z","iopub.status.idle":"2025-09-30T10:01:02.904299Z","shell.execute_reply.started":"2025-09-30T09:43:54.419286Z","shell.execute_reply":"2025-09-30T10:01:02.903529Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame({'ImageId': np.arange(1, len(preds)+1), 'Label': preds})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Saved to submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T10:01:22.571976Z","iopub.execute_input":"2025-09-30T10:01:22.57251Z","iopub.status.idle":"2025-09-30T10:01:22.599092Z","shell.execute_reply.started":"2025-09-30T10:01:22.572468Z","shell.execute_reply":"2025-09-30T10:01:22.598351Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Score 0.99367**","metadata":{}}]}